{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBLCaFAmt7SI"
      },
      "source": [
        "1. 스팸 메일 데이터 이해"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !apt-get install -y curl\n",
        "# !bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n"
      ],
      "metadata": {
        "id": "BGYrLTY-5JoL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab에 Mecab 설치\n",
        "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n",
        "%cd Mecab-ko-for-Google-Colab\n",
        "!bash install_mecab-ko_on_colab190912.sh"
      ],
      "metadata": {
        "id": "KxvLk6-06xLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TggsJn7IyAjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DQu4KcXL5Iy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__yvJZKpt_nO"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib.request\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import json\n",
        "from collections import Counter\n",
        "from konlpy.tag import Mecab\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b5ts3ny-2QMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "# import json\n",
        "\n",
        "# file_path = '/content/K2-00001-CL33762-CP33206-05-08-S2.json'\n",
        "\n",
        "# try:\n",
        "#     with open(file_path, 'r', encoding='utf-8') as file:\n",
        "#         datas = json.load(file)\n",
        "\n",
        "#         # 각 sessionInfo에 대해 반복\n",
        "#         utterance_list = []\n",
        "#         for session_info in datas.get('sessionInfo', []):\n",
        "#             dialog_list = session_info.get('dialog', [])\n",
        "\n",
        "#             # 각 dialog에 대해 반복\n",
        "#             for dialog in dialog_list:\n",
        "#                 utterance = dialog.get('utterance', '')\n",
        "#                 utterance_list.append(utterance)\n",
        "\n",
        "#         # 각 값을 엔터로 구분하여 출력\n",
        "#         print('\\n'.join(utterance_list))\n",
        "\n",
        "# except FileNotFoundError:\n",
        "#     print(f\"File not found: {file_path}\")\n",
        "# except Exception as e:\n",
        "#     print(f\"An error occurred: {e}\")\n"
      ],
      "metadata": {
        "id": "4nDjFNbGfPVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bN7g-SgruZrO"
      },
      "source": [
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/tonykorea99/Spam-alart/main/Spam%20Data.csv\", filename='Spam%20Data.csv')\n",
        "\n",
        "data = pd.read_csv('Spam%20Data.csv', encoding='utf-8')\n",
        "\n",
        "data = data.sample(frac=1, random_state=42)\n",
        "\n",
        "print('총 샘플의 수 :', len(data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIxFhTfhvBaH"
      },
      "source": [
        "data[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4NVlcUYJWX_X"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HG9WqivKvOrY"
      },
      "source": [
        "# 레이블과 메일 내용이 담긴 v1, v2 열만 필요 : unnamed 2-4 열은 삭제\n",
        "# 레이블 값을 0(ham), 1(spam)으로 변경\n",
        "\n",
        "\n",
        "data['v1'] = data['v1'].replace(['ham','spam'],[0,1])\n",
        "data[1199:1204]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wviaVdrgwR_T"
      },
      "source": [
        "# data의 정보 확인\n",
        "\n",
        "data.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLbatKMWwmqN"
      },
      "source": [
        "# null 값 포함 여부 확인\n",
        "\n",
        "data.isnull().values.any()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVItHYVOxU5X"
      },
      "source": [
        "# 중복 데이터 확인\n",
        "\n",
        "data['v2'].nunique(), data['v1'].nunique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiDexkB4xrWd"
      },
      "source": [
        "# 중복 데이터 제거\n",
        "\n",
        "data.drop_duplicates(subset=['v2'], inplace=True)\n",
        "\n",
        "print('총 샘플의 수 :',len(data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEAIyo3AyJ6h"
      },
      "source": [
        "# 레이블 값의 분포 시각화\n",
        "\n",
        "data['v1'].value_counts().plot(kind='bar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0B4YEyyyf5w"
      },
      "source": [
        "# 스팸 메일과 정상 메일 수치로 확인\n",
        "\n",
        "print(data.groupby('v1').size().reset_index(name='count'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tamS-dkw0Gi8"
      },
      "source": [
        "# X와 y를 분리합니다. v2열을 X, v1열을 y로 저장\n",
        "\n",
        "X_data = data['v2']\n",
        "y_data = data['v1']\n",
        "\n",
        "print('메일 본문의 개수: {}'.format(len(X_data)))\n",
        "print('레이블의 개수: {}'.format(len(y_data)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kmpr4Ffx0ps3"
      },
      "source": [
        "# 토큰화, 정수 인코딩"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmRoklhF1TVz"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_data) # 행을 가진 X의 각 행에 토큰화를 수행\n",
        "sequences = tokenizer.texts_to_sequences(X_data) # 단어를 숫자값, 인덱스로 변환하여 저장"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGly89lf1as9"
      },
      "source": [
        "print(sequences[:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOe2zvHx1fYb"
      },
      "source": [
        "# 각 정수가 어떤 단어에 부여되었는지 확인\n",
        "\n",
        "word_to_index = tokenizer.word_index\n",
        "print(word_to_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_Y7ECBS1lEH"
      },
      "source": [
        "# tokenizer.word_counts.items()를 사용하여 각 단어의 등장 빈도수 확인\n",
        "\n",
        "threshold = 2\n",
        "total_cnt = len(word_to_index) # 단어의 수\n",
        "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
        "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
        "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
        "\n",
        "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
        "for key, value in tokenizer.word_counts.items():\n",
        "    total_freq = total_freq + value\n",
        "\n",
        "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
        "    if(value < threshold):\n",
        "        rare_cnt = rare_cnt + 1\n",
        "        rare_freq = rare_freq + value\n",
        "\n",
        "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
        "print(\"단어 집합(vocabulary)에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
        "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odUJ1pDG2PcA"
      },
      "source": [
        "#단어 집합의 크기를 제한하진 않고 답어 집합 크기 설정\n",
        "\n",
        "vocab_size = len(word_to_index) + 1   # 패딩을 위한 토큰인 0번 단어를 고려하며 +1을 해서 저장\n",
        "print('단어 집합의 크기: {}'.format((vocab_size)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XkiFUdr49vP"
      },
      "source": [
        "# 훈련 데이터와 테스트 데이터 8:2 분리\n",
        "\n",
        "n_of_train = int(len(sequences) * 0.8)\n",
        "n_of_test = int(len(sequences) - n_of_train)\n",
        "print('훈련 데이터의 개수 :',n_of_train)\n",
        "print('테스트 데이터의 개수:',n_of_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbIPoTgH5JOv"
      },
      "source": [
        "# X_data에 대해서 정수 인코딩 된 결과인 sequences를 X_data로 변경하고,\n",
        "# 전체 데이터에서 가장 길이가 긴 메일과 전체 메일 데이터의 길이 분포 확인\n",
        "\n",
        "X_data = sequences\n",
        "print('메일의 최대 길이 : %d' % max(len(l) for l in X_data))\n",
        "print('메일의 평균 길이 : %f' % (sum(map(len, X_data))/len(X_data)))\n",
        "plt.hist([len(s) for s in X_data], bins=50)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUUyL3s35glG"
      },
      "source": [
        "# 패딩\n",
        "\n",
        "max_len = 559\n",
        "# 전체 데이터셋의 길이는 max_len으로 맞춥니다.\n",
        "data = pad_sequences(X_data, maxlen = max_len)\n",
        "print(\"훈련 데이터의 크기(shape): \", data.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJ-XOiNT53vI"
      },
      "source": [
        "# 훈련 데이터(X_train)와 테스트 데이터(X_test) 분리\n",
        "\n",
        "X_test = data[n_of_train:]\n",
        "y_test = np.array(y_data[n_of_train:])\n",
        "X_train = data[:n_of_train]\n",
        "y_train = np.array(y_data[:n_of_train])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBYGxw8q6aHZ"
      },
      "source": [
        "2. biLSTM으로 스팸 메일 분류하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-4L-iz-6d0a"
      },
      "source": [
        "# 모델 설계"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXQAchn86hfl"
      },
      "source": [
        "import re\n",
        "from tensorflow.keras.layers import Embedding, Dense,LSTM , Bidirectional\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.metrics import f1_score as sklearn_f1_score\n",
        "from keras.metrics import Precision, Recall"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def custom_f1_score(y_true, y_pred):\n",
        "    y_true = K.cast(K.round(y_true), 'float32')\n",
        "    y_pred = K.cast(K.round(y_pred), 'float32')\n",
        "\n",
        "    tp = K.sum(y_true * y_pred, axis=0)\n",
        "    fp = K.sum((1 - y_true) * y_pred, axis=0)\n",
        "    fn = K.sum(y_true * (1 - y_pred), axis=0)\n",
        "\n",
        "    precision = tp / (tp + fp + K.epsilon())\n",
        "    recall = tp / (tp + fn + K.epsilon())\n",
        "\n",
        "    f1 = 2 * precision * recall / (precision + recall + K.epsilon())\n",
        "    return K.mean(f1)"
      ],
      "metadata": {
        "id": "iMfvv1DDtEy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5rFytSC6kml"
      },
      "source": [
        "embedding_dim = 100\n",
        "hidden_units =128\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim))\n",
        "model.add(Bidirectional(LSTM(hidden_units)))  # BiLSTM사용\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
        "mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "history = model.fit(X_train, y_train, epochs=15, callbacks=[es, mc], batch_size=256, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IB124ije6nXO"
      },
      "source": [
        "# 모델 훈련\n",
        "\n",
        "# model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc', Precision(), Recall(), custom_f1_score])\n",
        "# history = model.fit(X_train, y_train, epochs=4, batch_size=64, validation_split=0.2)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3q5EaRKh64Q5"
      },
      "source": [
        "# 테스트 데이터에 대한 정확도\n",
        "\n",
        "result = model.evaluate(X_test, y_test, return_dict=True)\n",
        "print(\"\\n 테스트 결과:\", result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CM4Gm24v7Tvv"
      },
      "source": [
        "# 훈련 데이터와 검증 데이터에 대한 정확도 비교\n",
        "\n",
        "epochs = range(1, len(history.history['acc']) + 1)\n",
        "plt.plot(epochs, history.history['loss'])\n",
        "plt.plot(epochs, history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jc0MxeWE7oHu"
      },
      "source": [
        "def sentiment_predict(new_sentence):\n",
        "  new_sentence = re.sub(r'[^ㄱ-ㅎㅏ-ㅣ가-힣 ]','', new_sentence)\n",
        "  new_sentence = mecab.morphs(new_sentence) # 토큰화\n",
        "  new_sentence = [word for word in new_sentence if not word in stopwords] # 불용어 제거\n",
        "  encoded = tokenizer.texts_to_sequences([new_sentence]) # 정수 인코딩\n",
        "  pad_new = pad_sequences(encoded, maxlen = max_len) # 패딩\n",
        "  score = float(loaded_model.predict(pad_new)) # 예측\n",
        "  if(score > 0.5):\n",
        "    print(\"{:.2f}% 확률로 긍정 리뷰입니다.\".format(score * 100))\n",
        "  else:\n",
        "    print(\"{:.2f}% 확률로 부정 리뷰입니다.\".format((1 - score) * 100))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}