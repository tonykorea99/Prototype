{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYhu6rT5KckI",
        "outputId": "bd354f49-273a-499c-fabc-adf17ed3be4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting JPype1>=0.7.0 (from konlpy)\n",
            "  Downloading JPype1-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (488 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m488.6/488.6 kB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.4)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (23.2)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.5.0 konlpy-0.6.0\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install konlpy\n",
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FMPPsrUKeQF",
        "outputId": "1150431a-b866-4dd3-f6e7-3fb012978001"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3_bVj5NLJOf",
        "outputId": "2155e6ee-9839-4258-f9b5-f5a9ad8930a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 샘플의 수: 13549\n",
            "총 샘플의 수: 13477\n",
            "Epoch 1/5\n",
            "45/45 [==============================] - 22s 363ms/step - loss: 0.3766 - accuracy: 0.8417 - val_loss: 0.0640 - val_accuracy: 0.9812\n",
            "Epoch 2/5\n",
            "45/45 [==============================] - 15s 347ms/step - loss: 0.0137 - accuracy: 0.9979 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
            "Epoch 3/5\n",
            "45/45 [==============================] - 15s 328ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
            "Epoch 4/5\n",
            "45/45 [==============================] - 14s 322ms/step - loss: 5.1332e-04 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 0.9937\n",
            "Epoch 5/5\n",
            "45/45 [==============================] - 13s 300ms/step - loss: 3.4316e-04 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 0.9937\n",
            "13/13 [==============================] - 2s 80ms/step - loss: 3.7123e-04 - accuracy: 1.0000\n",
            "Accuracy: 100.00%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib.request\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from konlpy.tag import Okt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# 데이터 불러오기\n",
        "try:\n",
        "    urllib.request.urlretrieve(\"https://raw.githubusercontent.com/tonykorea99/Spam-alart/main/dd.csv\", filename='dd.csv')\n",
        "    data = pd.read_csv('dd.csv', encoding='utf-8')\n",
        "    data = data.sample(frac=1, random_state=42)\n",
        "    print('총 샘플의 수:', len(data))\n",
        "except Exception as e:\n",
        "    print('에러 발생:', e)\n",
        "\n",
        "# 레이블과 메일 내용이 담긴 v1, v2 열만 필요하며, unnamed 2-4 열은 삭제\n",
        "data = data[['v1', 'v2']]\n",
        "\n",
        "# 레이블 값을 0(ham), 1(spam)으로 변경\n",
        "data['v1'] = data['v1'].replace(['ham', 'spam'], [0, 1])\n",
        "\n",
        "# 중복 데이터 제거\n",
        "data.drop_duplicates(subset=['v2'], inplace=True)\n",
        "print('총 샘플의 수:', len(data))\n",
        "\n",
        "# 스팸과 일반 메시지를 각각 1000개씩 뽑아내기\n",
        "spam_data = data[data['v1'] == 1].head(1000)\n",
        "ham_data = data[data['v1'] == 0].head(1000)\n",
        "\n",
        "# 불용어 정의 (필요시 추가)\n",
        "stopwords = ['도', '는', '다', '의', '가', '이', '은', '한', '에', '하', '고', '을', '를', '인', '듯', '과','ifg', '와', '네', '들', '듯', '지', '임', '게', '만', '되', '음', '면']\n",
        "\n",
        "# 형태소 분리 및 토크나이징\n",
        "def preprocess_text(text):\n",
        "    okt = Okt()\n",
        "    tokens = okt.morphs(text)\n",
        "    tokens = [word for word in tokens if not word in stopwords]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "spam_data['v2'] = spam_data['v2'].apply(preprocess_text)\n",
        "ham_data['v2'] = ham_data['v2'].apply(preprocess_text)\n",
        "\n",
        "# 스팸과 일반 메시지 데이터 합치기\n",
        "final_data = pd.concat([spam_data, ham_data], axis=0)\n",
        "\n",
        "# 데이터 섞기\n",
        "final_data = final_data.sample(frac=1, random_state=42)\n",
        "\n",
        "# 레이블 및 데이터 분리\n",
        "y = final_data['v1'].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(final_data['v2'], y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 토크나이저 및 패딩\n",
        "max_len = 3039  # 최대 길이 설정\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train_tokenized = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_tokenized = tokenizer.texts_to_sequences(X_test)\n",
        "X_train_padded = pad_sequences(X_train_tokenized, maxlen=max_len, padding='post')\n",
        "X_test_padded = pad_sequences(X_test_tokenized, maxlen=max_len, padding='post')\n",
        "\n",
        "# BiLSTM 모델 정의\n",
        "model_lstm = Sequential()\n",
        "model_lstm.add(Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=100, input_length=max_len))\n",
        "model_lstm.add(Bidirectional(LSTM(128)))\n",
        "model_lstm.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# 모델 컴파일\n",
        "model_lstm.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# 모델 훈련\n",
        "model_lstm.fit(X_train_padded, y_train, epochs=5, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# 모델 평가\n",
        "loss, accuracy = model_lstm.evaluate(X_test_padded, y_test)\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCSazhcBOQEQ",
        "outputId": "77c1cd84-3516-4c80-8669-7f86f364dc7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected Data - Spam Count: 1000\n",
            "Selected Data - Ham Count: 1000\n"
          ]
        }
      ],
      "source": [
        "print(\"Selected Data - Spam Count:\", len(spam_data))\n",
        "print(\"Selected Data - Ham Count:\", len(ham_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B02YRfs3OpbV",
        "outputId": "7497c915-cbdc-43d8-8196-fe2aeaac10f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "첫 번째 스팸 메시지:\n",
            "[ Web 발신 ] @( 광고 ) 김영기 고객 님 ifg@ifg @ ★ 전북 은행 이용 중 고객 님 께 드리는 특별한 혜택 ★ @ ① 무 방문 , 무 서류 , 무 보증 @ ② 전화 신청 만으로 당일 입금 @ ③ 고금 리카 드론 , 현금 서비스 , * 금융 권 대출 대 환 ifg@ifg @ ★ 전북 은행 언 택트 금융 센터 @ ☎ ****-**** 담당 직원 조 유미 과장 ifg@ifg @ □ 대상 : 기존 전북 은행 에서 대출 또는 신용카드 보유 고객 님 @ 상품 : 스피드 론 * @ 한도 : 최대 * 천만원 이내 @ 대상 : 연 소득 ** 백만원 이상 ( KCB 결정 연 소득 또는 건강 보험료 환산 소득 ) @( KCB , NICE ) CB 점수 구간 ** 구간 내 인자 @ 금리 : 최저 연 *.**%~ 최고 연 **%(* 개월 변동 금리 , 대출 기간 * 년 , 연 소득 * 천만원 ,**.*.** 기준 ) @ 기준금리 : 시장 기준금리 ( 금융채 AA +)* 개월 변동 : 연 *.**% 가산 금리 : 연 *.**~**.**( 신용등급 별 차등 ) @ 대출 기간 : 최소 * 년 ~ 최대 * 년 ( 연 단위 ) @ 상환 방법 : 원리금 균등 분할 상환 @ 중도 상환 수수료 :*.*% 대출 실행 후 * 개 월경 시 면제 이자 납부 시기 : 매월 이자 납입 일후 취 @ 금리인하 요구 권 : 대상 인지세 : 비 과세 @ ▷ 계약 체결 전 상품 설명 서 및 약관 읽어 보시기 바랍니다 @ ▷ 연체 시 지연 배상금 률 ( 약정 이자율 +*%, 최고 연 **%) 발생 하며 채무자 재산 / 신용 상의 불이익 ( 기한 이익 상실 등 ) 발생 할 수 있습니다 @ ▷ 상환 능력 비해 대 출금 과도 할 경우 개인 신용 평점 하락 할수있으며 , 따라 금융 거래 관련 된 불이익 발생 할수있습니다 . @ ▷ 일정 기간 원리금 연체 될 경우 계약 만료 도래 전 모든 원리금 변제 하는 의무 발생 할수있습니다 @ ▷ 금융기관 신용 관리 대상 고객 등 당 행및 보증 기관 에서 정 대출 부적 격자 대하 여 대출 제한 될 수 있습니다 @ ▷ 금융 소비자보호법 제 ** 조 * 항 따라 상품 설명 받으실 권리 있습니다 @ ▷ 법령 및 내부통제 기준 따라 작성 된 자료 입니다 ifg@ifg @ 본 SMS 고객 님 께서 **** 년 ** 월 ** 일 SMS 수신 동의 하였기에 발송 되었습니다 . @ 준법 감시 심의 필 : 제 ****- 나 -** 호 ( 유효 기간 :****.**.** 까지 ) @ 무료 수신 거부 ***-***-****\n",
            "\n",
            "첫 번째 일반 메시지:\n",
            "제 콩국수 싫어해서요 . 어떻게 거절 할까 요 ?\n"
          ]
        }
      ],
      "source": [
        "print(\"첫 번째 스팸 메시지:\")\n",
        "print(spam_data['v2'].values[0])\n",
        "\n",
        "# 첫 번째 일반 메시지 출력\n",
        "print(\"\\n첫 번째 일반 메시지:\")\n",
        "print(ham_data['v2'].values[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MI-8Gq00OdAD"
      },
      "outputs": [],
      "source": [
        "# 입력한 문장이 스미싱인지 일반 메시지인지 판별하는 함수\n",
        "def classify_smishing(input_text):\n",
        "    input_text = preprocess_text(input_text)\n",
        "    encoded = tokenizer.texts_to_sequences([input_text])\n",
        "    pad_tokens = pad_sequences(encoded, maxlen=max_len)\n",
        "    smishing_score = float(model_lstm.predict(pad_tokens))\n",
        "\n",
        "    if smishing_score > 0.5:\n",
        "        print(\"{:.2f}% 확률로 스미싱입니다.\".format(smishing_score * 100))\n",
        "    else:\n",
        "        print(\"{:.2f}% 확률로 일반 메시지입니다.\".format((1 - smishing_score) * 100))\n",
        "\n",
        "# 사용자로부터 텍스트 입력 받기\n",
        "user_input_text = input(\"텍스트를 입력하세요: \")\n",
        "\n",
        "# 스미싱 여부 판단 수행\n",
        "classify_smishing(user_input_text)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}